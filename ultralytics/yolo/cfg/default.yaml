# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# Default training settings and hyperparameters for medium-augmentation COCO training
# YOLO æ¨¡å‹çš„é…ç½®æ–‡ä»¶ï¼Œå‚æ•°å¦‚ä¸‹ï¼š

task: detect  # YOLO task, i.e. detect, segment, classify, pose ï¼šYOLOä»»åŠ¡ç±»å‹ï¼Œæ­¤å¤„ä¸ºç›®æ ‡æ£€æµ‹ã€‚
mode: train  # YOLO mode, i.e. train, val, predict, export, track, benchmark ï¼šYOLOæ¨¡å¼ï¼Œæ­¤å¤„ä¸ºè®­ç»ƒæ¨¡å¼ã€‚

# Train settings -------------------------------------------------------------------------------------------------------
model: /root/autodl-tmp/yolov8/weights/v4s.pt # (æ·»åŠ )path to model file, i.e. yolov8n.pt, yolov8n.yaml ï¼šæ¨¡å‹æ–‡ä»¶çš„è·¯å¾„ï¼Œå€¼å®šä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹çš„ä½ç½®ã€‚
data: /root/autodl-tmp/yolov8/ultralytics/datasets/bdd-multi.yaml # (æ·»åŠ )path to data file, i.e. coco128.yaml ï¼šæ•°æ®æ–‡ä»¶è·¯å¾„ï¼ŒæŒ‡å®šä¸€ä¸ªæ•°æ®é›†æ–‡ä»¶çš„ä½ç½®ã€‚
epochs: 100  # number of epochs to train forï¼šè®­ç»ƒçš„è½®æ•°
patience: 50  # epochs to wait for no observable improvement for early stopping of training: å½“è¿ç»­å¤šå°‘ä¸ªè½®æ¬¡æ²¡æœ‰è§‚å¯Ÿåˆ°æ”¹è¿›æ—¶ï¼Œæå‰åœæ­¢è®­ç»ƒã€‚
batch: 16  # number of images per batch (-1 for AutoBatch): æ¯ä¸ªæ‰¹æ¬¡ä¸­çš„å›¾åƒæ•°é‡ã€‚
imgsz: 640  # size of input images as integer or w,h: è¾“å…¥å›¾åƒçš„å¤§å°ã€‚
save: True  # save train checkpoints and predict results: æ˜¯å¦ä¿å­˜è®­ç»ƒçš„æ£€æŸ¥ç‚¹å’Œé¢„æµ‹ç»“æœã€‚
save_period: 20 # (ä¿®æ”¹-1)Save checkpoint every x epochs (disabled if < 1): æ¯éš”å¤šå°‘ä¸ªè½®æ¬¡ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœå°äº1ï¼Œåˆ™ç¦ç”¨ï¼‰ã€‚
cache: True  # True/ram, disk or False. Use cache for data loading: æ•°æ®åŠ è½½æ—¶æ˜¯å¦ä½¿ç”¨ç¼“å­˜ã€‚
device: 0 # (æ·»åŠ )device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu: è¿è¡Œæ¨¡å‹çš„è®¾å¤‡ï¼Œ0 è¡¨ç¤ºä½¿ç”¨ç¬¬ä¸€ä¸ª GPU è®¾å¤‡ï¼Œå¦‚æœæ˜¯ -1 æˆ–è€… cpu åˆ™è¡¨ç¤ºä½¿ç”¨ CPUã€‚
workers: 8  # number of worker threads for data loading (per RANK if DDP): æ•°æ®åŠ è½½çš„å·¥ä½œçº¿ç¨‹æ•°ã€‚
project: # (æ·»åŠ )project name: é¡¹ç›®åç§°ã€‚
name: /root/autodl-tmp/yolov8/runs/multi/ # (æ·»åŠ )experiment name, results saved to 'project/name' directory: å®éªŒåç§°ï¼Œç»“æœå°†ä¿å­˜åœ¨ "project/name" ç›®å½•ä¸­ã€‚
exist_ok: True  #(ä¿®æ”¹) whether to overwrite existing experiment: æ˜¯å¦è¦†ç›–ç°æœ‰å®éªŒç»“æœã€‚
pretrained: True  #(ä¿®æ”¹) whether to use a pretrained model: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ã€‚
optimizer: SGD  # optimizer to use, choices=['SGD', 'Adam', 'AdamW', 'RMSProp'] ä¼˜åŒ–å™¨ç±»å‹ï¼Œé€‰æ‹©['SGD', 'Adam', 'AdamW', 'RMSProp']ä¹‹ä¸€ã€‚
verbose: True  # whether to print verbose output: æ˜¯å¦æ‰“å°è¯¦ç»†è¾“å‡ºã€‚
seed: 0  # random seed for reproducibility: éšæœºç§å­ï¼Œç”¨äºå¯é‡å¤æ€§ã€‚
deterministic: True  # whether to enable deterministic mode: æ˜¯å¦å¯ç”¨ç¡®å®šæ€§æ¨¡å¼ã€‚
single_cls: False  # train multi-class data as single-class: æ˜¯å¦å°†å¤šç±»æ•°æ®è§†ä¸ºå•ç±»æ¥è®­ç»ƒã€‚single_cls: False è¡¨ç¤ºæ¨¡å‹ç”¨äºå¤šç±»åˆ«ä»»åŠ¡ï¼Œå¯ä»¥æ£€æµ‹å’Œåˆ†ç±»å¤šä¸ªä¸åŒç±»åˆ«çš„ç›®æ ‡ã€‚è€Œ single_cls: True è¡¨ç¤ºæ¨¡å‹ç”¨äºå•ç±»åˆ«ä»»åŠ¡ï¼Œåªå…³æ³¨ä¸€ä¸ªç‰¹å®šç±»åˆ«çš„ç›®æ ‡ã€‚
combine_class: None # ç»„åˆçš„ç±»åˆ«åˆ—è¡¨ã€‚è¡¨ç¤ºæ¨¡å‹å°†â€œç±»â€åˆå¹¶ä¸ºä¸€ä¸ªç±»ï¼Œä¾‹å¦‚æˆ‘ä»¬çš„é¡¹ç›®å°†â€œæ±½è½¦â€ã€â€œå…¬å…±æ±½è½¦â€ã€â€œå¡è½¦â€å’Œâ€œç«è½¦â€ç»„åˆæˆâ€œè½¦è¾†â€ã€‚
rect: False  # rectangular training if mode='train' or rectangular validation if mode='val'å¦‚æœæ˜¯'mode=train'åˆ™è¿›è¡ŒçŸ©å½¢è®­ç»ƒï¼Œå¦‚æœæ˜¯'mode=val'åˆ™è¿›è¡ŒçŸ©å½¢éªŒè¯ã€‚
cos_lr: True  # (è‡ªæ”¹)use cosine learning rate scheduler: æ˜¯å¦ä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚
close_mosaic: 0  # (int) disable mosaic augmentation for final epochs: ç¦ç”¨æ··åˆå¢å¼ºçš„æœ€åå‡ ä¸ªè½®æ¬¡ã€‚
resume: False  # resume training from last checkpoint: æ˜¯å¦ä»ä¸Šæ¬¡æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚
amp: True  # Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check: æ˜¯å¦ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆAMPï¼‰è®­ç»ƒã€‚
# Segmentation
overlap_mask: True  # masks should overlap during training (segment train only): åœ¨è®­ç»ƒæœŸé—´ï¼Œæ ‡æ³¨çš„åˆ†å‰²é®ç½©æ˜¯å¦åº”è¯¥é‡å ï¼ˆä»…é€‚ç”¨äºåˆ†å‰²è®­ç»ƒï¼‰ã€‚
mask_ratio: 1  # mask downsample ratio (segment train only): åˆ†å‰²é®ç½©çš„é™é‡‡æ ·æ¯”ä¾‹ï¼ˆä»…é€‚ç”¨äºåˆ†å‰²è®­ç»ƒï¼‰ã€‚
# Classification
dropout: 0.0  # use dropout regularization (classify train only): æ˜¯å¦ä½¿ç”¨ dropout æ­£åˆ™åŒ–ï¼ˆä»…é€‚ç”¨äºåˆ†ç±»è®­ç»ƒï¼‰ã€‚

# Val/Test settings ----------------------------------------------------------------------------------------------------
val: True  # validate/test during training: åœ¨è®­ç»ƒæœŸé—´æ˜¯å¦è¿›è¡ŒéªŒè¯/æµ‹è¯•ã€‚
split: val  # dataset split to use for validation, i.e. 'val', 'test' or 'train': ç”¨äºéªŒè¯çš„æ•°æ®é›†æ‹†åˆ†ï¼Œå¯ä»¥é€‰æ‹© 'val'ã€'test' æˆ– 'train'ã€‚
save_json: True  # save results to JSON file: æ˜¯å¦å°†ç»“æœä¿å­˜ä¸º JSON æ–‡ä»¶ã€‚
save_hybrid: False  # save hybrid version of labels (labels + additional predictions): æ˜¯å¦ä¿å­˜æ ‡ç­¾çš„æ··åˆç‰ˆæœ¬ï¼ˆåŒ…å«æ ‡ç­¾å’Œé¢å¤–çš„é¢„æµ‹ç»“æœï¼‰ã€‚
conf:  # object confidence threshold for detection (default 0.25 predict, 0.001 val): æ£€æµ‹æ—¶çš„ç›®æ ‡ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆé»˜è®¤å€¼ 0.25 ç”¨äºé¢„æµ‹ï¼Œ0.001 ç”¨äºéªŒè¯ï¼‰ã€‚
iou: 0.7  # intersection over union (IoU) threshold for NMS: éæå¤§å€¼æŠ‘åˆ¶ (NMS) çš„äº¤å¹¶æ¯”ï¼ˆIoUï¼‰é˜ˆå€¼ã€‚
max_det: 300  # maximum number of detections per image: æ¯å¼ å›¾åƒçš„æœ€å¤§æ£€æµ‹æ•°é‡ã€‚
half: False  # use half precision (FP16): æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦ï¼ˆFP16ï¼‰ã€‚
dnn: False  # use OpenCV DNN for ONNX inference: æ˜¯å¦ä½¿ç”¨ OpenCV DNN è¿›è¡Œ ONNX æ¨æ–­ã€‚
plots: True  # save plots during train/val: åœ¨è®­ç»ƒ/éªŒè¯æœŸé—´æ˜¯å¦ä¿å­˜ç»˜å›¾ç»“æœã€‚
speed: True # ###liuya### calculate the fps follow the hybridnet https://github.com/datvuthanh/HybridNets/blob/main/hybridnets_test.py#L211: æ˜¯å¦è®¡ç®—æ¯ç§’å¤„ç†çš„å¸§æ•°ï¼ˆæ ¹æ® HybridNet è®¡ç®—ï¼Œå‚è€ƒé“¾æ¥ï¼‰ã€‚

# Prediction settings --------------------------------------------------------------------------------------------------
source: /root/autodl-tmp/yolov8/ultralytics/assets/bus.jpg # (æ·»åŠ )source directory for images or videos: å›¾åƒæˆ–è§†é¢‘æºçš„è·¯å¾„ã€‚
show: False  # show results if possible: å¦‚æœå¯èƒ½ï¼Œæ˜¯å¦æ˜¾ç¤ºç»“æœã€‚
save_txt: False  # save results as .txt file: æ˜¯å¦å°†ç»“æœä¿å­˜ä¸º .txt æ–‡ä»¶ã€‚
save_conf: False  # save results with confidence scores: æ˜¯å¦ä¿å­˜å¸¦æœ‰ç½®ä¿¡åº¦åˆ†æ•°çš„ç»“æœã€‚
save_crop: False  # save cropped images with results: æ˜¯å¦å°†è£å‰ªåçš„å›¾åƒä¸ç»“æœä¸€èµ·ä¿å­˜ã€‚
show_labels: True  # show object labels in plots: æ˜¯å¦åœ¨ç»˜å›¾ä¸­æ˜¾ç¤ºå¯¹è±¡æ ‡ç­¾ã€‚æ ‡ç­¾å°†é»˜è®¤æ˜¾ç¤ºç¬¬ä¸€ä¸ªç±»åã€‚
show_conf: True  # show object confidence scores in plots: æ˜¯å¦åœ¨ç»˜å›¾ä¸­æ˜¾ç¤ºå¯¹è±¡ç½®ä¿¡åº¦åˆ†æ•°ã€‚
vid_stride: 1  # video frame-rate stride: è§†é¢‘å¸§ç‡æ­¥é•¿ã€‚
line_width:   # line width of the bounding boxes: è¾¹ç•Œæ¡†çš„çº¿å®½ã€‚
visualize: False  # visualize model features: æ˜¯å¦å¯è§†åŒ–æ¨¡å‹ç‰¹å¾ã€‚
augment: False  # apply image augmentation to prediction sources: æ˜¯å¦å¯¹é¢„æµ‹æºåº”ç”¨å›¾åƒå¢å¼ºã€‚
agnostic_nms: False  # class-agnostic NMS: æ˜¯å¦ä½¿ç”¨ç±»åˆ«æ— å…³çš„éæå¤§å€¼æŠ‘åˆ¶ã€‚
classes: multi # filter results by class, i.e. class=0, or class=[0,2,3]: æ ¹æ®ç±»åˆ«è¿›è¡Œç»“æœè¿‡æ»¤ï¼Œä¾‹å¦‚class=0æˆ–class=[0,2,3]è¡¨ç¤ºåªä¿ç•™ç‰¹å®šç±»åˆ«çš„ç»“æœã€‚æ‚¨å¯ä»¥æ›´æ”¹æ­¤è®¾ç½®ä»¥æ§åˆ¶è®­ç»ƒä¸­çš„åˆ†ç±»ï¼Œ10 å’Œ 11 è¡¨ç¤ºå¯é©¾é©¶åŒºåŸŸå’Œè½¦é“çº¿åˆ†å‰²ã€‚æ‚¨å¯ä»¥åœ¨ â€œ./ultralytics/datasets/bdd-multi.yamlâ€ ä¸‹åˆ›å»ºæˆ–æ›´æ”¹æ•°æ®é›†æ˜ å°„
retina_masks: False  # use high-resolution segmentation masks: æ˜¯å¦ä½¿ç”¨é«˜åˆ†è¾¨ç‡åˆ†å‰²é®ç½©ã€‚
boxes: True  # Show boxes in segmentation predictions: åœ¨åˆ†å‰²é¢„æµ‹ä¸­æ˜¯å¦æ˜¾ç¤ºè¾¹ç•Œæ¡†ã€‚æ˜¯å¦å¼€å¯åˆ†æ®µä»»åŠ¡çš„ bosã€‚

# Export settings ------------------------------------------------------------------------------------------------------
format: torchscript  # format to export toï¼šå¯¼å‡ºçš„æ ¼å¼ä¸º TorchScriptã€‚
keras: False  # use Kerasï¼šæ˜¯å¦ä½¿ç”¨ Kerasã€‚
optimize: False  # TorchScript: optimize for mobileï¼šåœ¨ TorchScript ä¸­ä¸è¿›è¡Œä¼˜åŒ–ä»¥é€‚åº”ç§»åŠ¨è®¾å¤‡ã€‚
int8: False  # CoreML/TF INT8 quantizationï¼šCoreML/TF ä½¿ç”¨æ•´å‹ 8 ä½é‡åŒ–ã€‚
dynamic: False  # ONNX/TF/TensorRT: dynamic axesï¼šONNX/TF/TensorRT ä½¿ç”¨åŠ¨æ€è½´ã€‚
simplify: False  # ONNX: simplify modelï¼šONNX æ¨¡å‹ç®€åŒ–ã€‚
opset:  # ONNX: opset version (optional)ï¼šONNX çš„æ“ä½œé›†ç‰ˆæœ¬ï¼ˆå¯é€‰ï¼‰ã€‚
workspace: 4  # TensorRT: workspace size (GB)ï¼šTensorRT çš„å·¥ä½œç©ºé—´å¤§å°ï¼ˆGBï¼‰ã€‚
nms: False  # CoreML: add NMSï¼šåœ¨ CoreML ä¸­æ·»åŠ éæå¤§å€¼æŠ‘åˆ¶ã€‚

# Hyperparameters ------------------------------------------------------------------------------------------------------
lr0: 0.01  # initial learning rate (i.e. SGD=1E-2, Adam=1E-3)ï¼šåˆå§‹å­¦ä¹ ç‡ï¼ˆä¾‹å¦‚ï¼ŒSGD=1E-2ï¼ŒAdam=1E-3ï¼‰ã€‚
lrf: 0.01  # final learning rate (lr0 * lrf)ï¼šæœ€ç»ˆå­¦ä¹ ç‡ï¼ˆlr0 * lrfï¼‰ã€‚
momentum: 0.937  # SGD momentum/Adam beta1ï¼šSGD åŠ¨é‡/Adam beta1ã€‚
weight_decay: 0.0005  # optimizer weight decay 5e-4ï¼šä¼˜åŒ–å™¨çš„æƒé‡è¡°å‡ï¼ˆ5e-4ï¼‰ã€‚
warmup_epochs: 3.0  # warmup epochs (fractions ok)ï¼šé¢„çƒ­é˜¶æ®µçš„è®­ç»ƒè½®æ•°ï¼ˆå¯ä»¥ä½¿ç”¨å°æ•°è¡¨ç¤ºéƒ¨åˆ†è½®æ•°ï¼‰ã€‚
warmup_momentum: 0.8  # warmup initial momentumï¼šé¢„çƒ­é˜¶æ®µçš„åˆå§‹åŠ¨é‡ã€‚
warmup_bias_lr: 0.1  # warmup initial bias lrï¼šé¢„çƒ­é˜¶æ®µçš„åˆå§‹åç½®å­¦ä¹ ç‡ã€‚
box: 7.5  # box loss gainï¼šè¾¹ç•Œæ¡†æŸå¤±å¢ç›Šã€‚
cls: 0.5  # cls loss gain (scale with pixels)ï¼šåˆ†ç±»æŸå¤±å¢ç›Šï¼ˆä¸åƒç´ ç¼©æ”¾æ¯”ä¾‹ç›¸å…³ï¼‰ã€‚
dfl: 1.5  # dfl loss gainï¼šè‡ªç”±å½¢å˜æŸå¤±å¢ç›Šã€‚
TL: 8.0 # TL loss gainï¼šTLï¼ˆç›®æ ‡åˆ—è¡¨ï¼‰æŸå¤±å¢ç›Šã€‚
FL: 24.0 # FL loss for segment gainï¼šFLï¼ˆåˆ†å‰²ï¼‰æŸå¤±å¢ç›Šã€‚
pose: 12.0  # pose loss gainï¼šå§¿æ€æŸå¤±å¢ç›Šã€‚
kobj: 1.0  # keypoint obj loss gainï¼šå…³é”®ç‚¹ç›®æ ‡æŸå¤±å¢ç›Šã€‚
label_smoothing: 0.0  # label smoothing (fraction)ï¼šæ ‡ç­¾å¹³æ»‘åŒ–ï¼ˆæ¯”ä¾‹ï¼‰ã€‚
nbs: 64  # nominal batch sizeï¼šæ‰¹é‡å¤§å°ã€‚
hsv_h: 0.015  # image HSV-Hue augmentation (fraction)ï¼šå›¾åƒ HSV-Hue è°ƒæ•´ï¼ˆæ¯”ä¾‹ï¼‰ã€‚
hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)ï¼šå›¾åƒ HSV-Saturation è°ƒæ•´ï¼ˆæ¯”ä¾‹ï¼‰ã€‚
hsv_v: 0.4  # image HSV-Value augmentation (fraction)ï¼šå›¾åƒ HSV-Value è°ƒæ•´ï¼ˆæ¯”ä¾‹ï¼‰ã€‚
degrees: 0.0  # image rotation (+/- deg)ï¼šå›¾åƒæ—‹è½¬è§’åº¦ï¼ˆ+/- åº¦ï¼‰ã€‚
translate: 0.1  # image translation (+/- fraction)ï¼šå›¾åƒå¹³ç§»ï¼ˆ+/- æ¯”ä¾‹ï¼‰ã€‚
scale: 0.5  # image scale (+/- gain)ï¼šå›¾åƒç¼©æ”¾ï¼ˆ+/- å¢ç›Šï¼‰ã€‚
shear: 0.0  # image shear (+/- deg)ï¼šå›¾åƒå‰ªåˆ‡ï¼ˆ+/- åº¦ï¼‰ã€‚
perspective: 0.0  # image perspective (+/- fraction), range 0-0.001ï¼šå›¾åƒé€è§†å˜æ¢ï¼ˆ+/- æ¯”ä¾‹ï¼‰ï¼ŒèŒƒå›´ä¸º 0-0.001ã€‚
flipud: 0.0  # image flip up-down (probability)ï¼šå›¾åƒä¸Šä¸‹ç¿»è½¬çš„æ¦‚ç‡ã€‚
fliplr: 0.5  # image flip left-right (probability)ï¼šå›¾åƒå·¦å³ç¿»è½¬çš„æ¦‚ç‡ã€‚
mosaic: 1.0  # image mosaic (probability)ï¼šå›¾åƒé©¬èµ›å…‹åŒ–çš„æ¦‚ç‡ã€‚
mixup: 0.0  # image mixup (probability)å›¾åƒæ··åˆçš„æ¦‚ç‡ã€‚
copy_paste: 0.0  # segment copy-paste (probability)ï¼šåˆ†å‰²ä»»åŠ¡ä¸­å¤åˆ¶ç²˜è´´çš„æ¦‚ç‡ã€‚
binary_mask_threshold: 0.5  # segment task binary mask thresholdï¼šåˆ†å‰²ä»»åŠ¡çš„äºŒå€¼åŒ–é˜ˆå€¼ã€‚

# Custom config.yaml ---------------------------------------------------------------------------------------------------
cfg:  # for overriding defaults.yamlï¼šç”¨äºè¦†ç›– defaults.yaml çš„è‡ªå®šä¹‰é…ç½®ã€‚

# Debug, do not modify -------------------------------------------------------------------------------------------------
v5loader: False  # use legacy YOLOv5 dataloaderï¼šä½¿ç”¨æ—§ç‰ˆ YOLOv5 æ•°æ®åŠ è½½å™¨çš„è°ƒè¯•é€‰é¡¹ï¼Œä¸è¦ä¿®æ”¹ã€‚

# Tracker settings ------------------------------------------------------------------------------------------------------
tracker: botsort.yaml  # tracker type, ['botsort.yaml', 'bytetrack.yaml']ï¼šè·Ÿè¸ªå™¨ç±»å‹ï¼Œå¯é€‰æ‹© ['botsort.yaml', 'bytetrack.yaml']ã€‚
